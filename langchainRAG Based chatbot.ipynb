{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03851bb3-620f-4f17-8719-5070def13199",
   "metadata": {},
   "source": [
    "RESUME RAG: GEMINI-POWERED AI CHATBOT USING LANGCHAIN AND FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47437a1c-800a-4aeb-8dea-f69563e2b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt\n",
    "#(needed libraries are installed with version because of langchain may difficult when version error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b81fcac-c50e-4362-9120-e6ef31452158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = (\"AIzaSyD_9EysR3y0c1TGcr6weAbE-2DrZrxDcpI\")\n",
    "# gemini api key uploaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb52eb15-49dc-4d57-b00f-fd4219f12616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udhaya\\anaconda3\\envs\\agenticai\\Lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"Udhayakumar B Resume.pdf\")\n",
    "documents = loader.load()\n",
    "#my resume 2 pages uploaded in pdf format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9cdc65e-3366-46ba-8a59-0ba645f89aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=100)\n",
    "docs = splitter.split_documents(documents)\n",
    "#loaded 2 page resume splitted into varuious chunks due to easy retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d756ca3-c07a-4d67-958d-4d58920f83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cd40217-f335-4af9-a57d-24f67877bb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udhaya\\AppData\\Local\\Temp\\ipykernel_2744\\985639669.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Use HuggingFace embeddings (free, local)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# Store in FAISS\n",
    "vectorstore = FAISS.from_documents(\n",
    "    docs, \n",
    "    embeddings\n",
    ")\n",
    "\n",
    "# Save FAISS index locally\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "\n",
    "# Load it later (if needed)\n",
    "# vectorstore = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Convert to retriever\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e738a0-16b5-4e30-af48-a44f9174fcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000015864B4F6D0>, search_kwargs={})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980dcc51-9076-4cac-aa46-6cfc1e6177f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade langchain langchain-core langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ab934-691c-42c6-ac03-fd06bb8e10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Ensure Pydantic is on V2\n",
    "#!pip install \"pydantic>=2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccd90d25-3663-4686-bd9d-2794b6213f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# Use the official, current model name\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",temperature=0.2) # Or \"gemini-2.5-pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52bff1d4-8989-417d-bc41-67ecb56d816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Conversational RAG chain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc73e87-d2f7-4e56-a79a-c8ea99b80e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udhaya\\AppData\\Local\\Temp\\ipykernel_2744\\2732495484.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "#  Memory for chat history\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693600ee-7fb9-4c74-9b42-60f9d93fdc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Wrap RAG as a StructuredTool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import StructuredTool\n",
    "def rag_tool_fn(question: str) -> str:\n",
    "    return rag_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"chat_history\": []\n",
    "    })[\"answer\"]\n",
    "\n",
    "rag_tool = StructuredTool.from_function(\n",
    "    name=\"RAG_QA\",\n",
    "    description=\"Useful for answering questions about resume summary from the provided documents.\",\n",
    "    func=rag_tool_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b46f98c-d3f2-48b2-8eba-a05d9d8dbb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udhaya\\AppData\\Local\\Temp\\ipykernel_2744\\4265286962.py:2: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "#  Create agent\n",
    "agent = initialize_agent(\n",
    "    tools=[rag_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4cd1475-8e90-49db-af50-eb8a8e88cd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1️⃣ First question\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udhaya\\AppData\\Local\\Temp\\ipykernel_2744\\1193395386.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  res1 = agent.run(\"What are the skills mentioned?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: RAG_QA\n",
      "Action Input: What are the skills mentioned?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mHere are the skills mentioned:\n",
      "\n",
      "**SOFT SKILLS**\n",
      "*   Time management and organization\n",
      "*   Leadership and Initiative\n",
      "*   Technical support\n",
      "*   Communication Skills\n",
      "*   Maintenance planning and coordination\n",
      "*   Collaboration and Teamwork\n",
      "*   Material management and procurement\n",
      "*   Safety protocols and regulations\n",
      "*   Data analysis and reporting (Looker Studio)\n",
      "*   MS Word and documentation management\n",
      "\n",
      "**TECHNICAL SKILLS**\n",
      "*   SSD (Single Shot MultiBox Detector)\n",
      "*   MobileNet\n",
      "*   TensorFlow\n",
      "*   OpenCV\n",
      "*   Python\n",
      "*   NumPy\n",
      "*   Natural Language Processing (NLP)\n",
      "*   Generative AI\n",
      "*   Looker Studio\n",
      "*   EDA Data Processing\n",
      "*   Deployment\n",
      "*   Data Visualization\n",
      "*   Python Libraries (Numpy, Pandas, Matplotlib, Seaborn, Keras, TensorFlow)\n",
      "*   Machine Learning\n",
      "*   Deep Learning\n",
      "*   Time series Analysis\n",
      "*   SQL\n",
      "*   PowerBI\n",
      "*   LLM (Large Language Model)\n",
      "*   Asset Management\n",
      "*   AUTO CAD\n",
      "*   PRO-E\n",
      "*   Mechanical materials\n",
      "*   Vender Management\n",
      "*   AI Agent\n",
      "*   Specialised RAG based AI Agents\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: Here are the skills mentioned, categorized into soft and technical skills:\n",
      "\n",
      "**SOFT SKILLS**\n",
      "*   Time management and organization\n",
      "*   Leadership and Initiative\n",
      "*   Technical support\n",
      "*   Communication Skills\n",
      "*   Maintenance planning and coordination\n",
      "*   Collaboration and Teamwork\n",
      "*   Material management and procurement\n",
      "*   Safety protocols and regulations\n",
      "*   Data analysis and reporting (Looker Studio)\n",
      "*   MS Word and documentation management\n",
      "\n",
      "**TECHNICAL SKILLS**\n",
      "*   SSD (Single Shot MultiBox Detector)\n",
      "*   MobileNet\n",
      "*   TensorFlow\n",
      "*   OpenCV\n",
      "*   Python\n",
      "*   NumPy\n",
      "*   Natural Language Processing (NLP)\n",
      "*   Generative AI\n",
      "*   Looker Studio\n",
      "*   EDA Data Processing\n",
      "*   Deployment\n",
      "*   Data Visualization\n",
      "*   Python Libraries (Numpy, Pandas, Matplotlib, Seaborn, Keras, TensorFlow)\n",
      "*   Machine Learning\n",
      "*   Deep Learning\n",
      "*   Time series Analysis\n",
      "*   SQL\n",
      "*   PowerBI\n",
      "*   LLM (Large Language Model)\n",
      "*   Asset Management\n",
      "*   AUTO CAD\n",
      "*   PRO-E\n",
      "*   Mechanical materials\n",
      "*   Vender Management\n",
      "*   AI Agent\n",
      "*   Specialised RAG based AI Agents\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: Here are the skills mentioned, categorized into soft and technical skills:\n",
      "\n",
      "**SOFT SKILLS**\n",
      "*   Time management and organization\n",
      "*   Leadership and Initiative\n",
      "*   Technical support\n",
      "*   Communication Skills\n",
      "*   Maintenance planning and coordination\n",
      "*   Collaboration and Teamwork\n",
      "*   Material management and procurement\n",
      "*   Safety protocols and regulations\n",
      "*   Data analysis and reporting (Looker Studio)\n",
      "*   MS Word and documentation management\n",
      "\n",
      "**TECHNICAL SKILLS**\n",
      "*   SSD (Single Shot MultiBox Detector)\n",
      "*   MobileNet\n",
      "*   TensorFlow\n",
      "*   OpenCV\n",
      "*   Python\n",
      "*   NumPy\n",
      "*   Natural Language Processing (NLP)\n",
      "*   Generative AI\n",
      "*   Looker Studio\n",
      "*   EDA Data Processing\n",
      "*   Deployment\n",
      "*   Data Visualization\n",
      "*   Python Libraries (Numpy, Pandas, Matplotlib, Seaborn, Keras, TensorFlow)\n",
      "*   Machine Learning\n",
      "*   Deep Learning\n",
      "*   Time series Analysis\n",
      "*   SQL\n",
      "*   PowerBI\n",
      "*   LLM (Large Language Model)\n",
      "*   Asset Management\n",
      "*   AUTO CAD\n",
      "*   PRO-E\n",
      "*   Mechanical materials\n",
      "*   Vender Management\n",
      "*   AI Agent\n",
      "*   Specialised RAG based AI Agents\n",
      "\n",
      "2️⃣ Follow-up\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: RAG_QA\n",
      "Action Input: work experience details\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mHere are the work experience details from the provided text:\n",
      "\n",
      "**Key Responsibilities:**\n",
      "\n",
      "*   Utilized visual storytelling to improve marketing strategies and user engagement.\n",
      "*   Integrated advanced Looker Studio features for clear, actionable insights and data-driven decision-making.\n",
      "*   Analyzed website data for actionable insights.\n",
      "*   Conducted data analysis, visualization, and storytelling to drive informed decisions and enhance marketing strategies.\n",
      "*   Designed and implemented data integration solutions to provide clear, insightful reporting.\n",
      "*   Utilized dashboard design expertise to analyze customer channels, geographies, and target audiences effectively.\n",
      "*   Ensured compliance.\n",
      "*   Identified task activities by assigning work centers and ensuring the availability of materials, tools, and equipment.\n",
      "*   Maintained routine management records and ensured the smooth flow of daily operations.\n",
      "*   Monitored and controlled maintenance activities, including preventive, scheduled, breakdown, and shutdown tasks.\n",
      "*   Ensured effective resource utilization through close tracking of maintenance schedules and operations.\n",
      "*   Collaborated on AI-based projects, including data integration, model development, and dashboard creation, to support business goals.\n",
      "\n",
      "**Projects:**\n",
      "\n",
      "*   **Rag-Based Q&A System for Resume Analysis using Generative AI, ChromaDB VectorDatabase**\n",
      "    *   Designed and implemented a RAG-based Q&A system for extracting key information from resumes using Generative AI.\n",
      "    *   Integrated ChromaDB for efficient storage and retrieval of resume embeddings, enhancing system performance.\n",
      "*   **Real Time Project Dashboard using Looker Studio**\n",
      "    *   Participation Certificate of Real Time Project Dashboard using Looker Studio by HopeAI Technologies.\n",
      "    *   **Tools Used:** Looker Studio\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: Here are the work experience details:\n",
      "\n",
      "**Key Responsibilities:**\n",
      "*   Utilized visual storytelling to improve marketing strategies and user engagement.\n",
      "*   Integrated advanced Looker Studio features for clear, actionable insights and data-driven decision-making.\n",
      "*   Analyzed website data for actionable insights.\n",
      "*   Conducted data analysis, visualization, and storytelling to drive informed decisions and enhance marketing strategies.\n",
      "*   Designed and implemented data integration solutions to provide clear, insightful reporting.\n",
      "*   Utilized dashboard design expertise to analyze customer channels, geographies, and target audiences effectively.\n",
      "*   Ensured compliance.\n",
      "*   Identified task activities by assigning work centers and ensuring the availability of materials, tools, and equipment.\n",
      "*   Maintained routine management records and ensured the smooth flow of daily operations.\n",
      "*   Monitored and controlled maintenance activities, including preventive, scheduled, breakdown, and shutdown tasks.\n",
      "*   Ensured effective resource utilization through close tracking of maintenance schedules and operations.\n",
      "*   Collaborated on AI-based projects, including data integration, model development, and dashboard creation, to support business goals.\n",
      "\n",
      "**Projects:**\n",
      "*   **Rag-Based Q&A System for Resume Analysis using Generative AI, ChromaDB VectorDatabase**\n",
      "    *   Designed and implemented a RAG-based Q&A system for extracting key information from resumes using Generative AI.\n",
      "    *   Integrated ChromaDB for efficient storage and retrieval of resume embeddings, enhancing system performance.\n",
      "*   **Real Time Project Dashboard using Looker Studio**\n",
      "    *   Participation Certificate of Real Time Project Dashboard using Looker Studio by HopeAI Technologies.\n",
      "    *   **Tools Used:** Looker Studio\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: Here are the work experience details:\n",
      "\n",
      "**Key Responsibilities:**\n",
      "*   Utilized visual storytelling to improve marketing strategies and user engagement.\n",
      "*   Integrated advanced Looker Studio features for clear, actionable insights and data-driven decision-making.\n",
      "*   Analyzed website data for actionable insights.\n",
      "*   Conducted data analysis, visualization, and storytelling to drive informed decisions and enhance marketing strategies.\n",
      "*   Designed and implemented data integration solutions to provide clear, insightful reporting.\n",
      "*   Utilized dashboard design expertise to analyze customer channels, geographies, and target audiences effectively.\n",
      "*   Ensured compliance.\n",
      "*   Identified task activities by assigning work centers and ensuring the availability of materials, tools, and equipment.\n",
      "*   Maintained routine management records and ensured the smooth flow of daily operations.\n",
      "*   Monitored and controlled maintenance activities, including preventive, scheduled, breakdown, and shutdown tasks.\n",
      "*   Ensured effective resource utilization through close tracking of maintenance schedules and operations.\n",
      "*   Collaborated on AI-based projects, including data integration, model development, and dashboard creation, to support business goals.\n",
      "\n",
      "**Projects:**\n",
      "*   **Rag-Based Q&A System for Resume Analysis using Generative AI, ChromaDB VectorDatabase**\n",
      "    *   Designed and implemented a RAG-based Q&A system for extracting key information from resumes using Generative AI.\n",
      "    *   Integrated ChromaDB for efficient storage and retrieval of resume embeddings, enhancing system performance.\n",
      "*   **Real Time Project Dashboard using Looker Studio**\n",
      "    *   Participation Certificate of Real Time Project Dashboard using Looker Studio by HopeAI Technologies.\n",
      "    *   **Tools Used:** Looker Studio\n",
      "\n",
      "3️⃣ Ask again\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: This resume highlights a professional with a strong blend of technical and soft skills, primarily focused on data analysis, AI, and maintenance management.\n",
      "\n",
      "**Key Strengths:**\n",
      "\n",
      "*   **Data & AI Expertise:** Proficient in Machine Learning, Deep Learning, NLP, Generative AI, and tools like TensorFlow, Python (Numpy, Pandas, Matplotlib, Seaborn, Keras), SQL, PowerBI, and Looker Studio. Demonstrated experience in building RAG-based Q&A systems and real-time project dashboards.\n",
      "*   **Data Visualization & Storytelling:** Skilled in using Looker Studio for creating clear, actionable insights, improving marketing strategies, and driving data-driven decision-making.\n",
      "*   **Maintenance & Operations Management:** Experience in planning, coordinating, and monitoring maintenance activities (preventive, scheduled, breakdown), ensuring resource utilization, and managing materials and vendors.\n",
      "*   **Soft Skills:** Strong in time management, organization, leadership, communication, collaboration, and ensuring compliance and safety.\n",
      "\n",
      "**Work Experience Highlights:**\n",
      "\n",
      "The individual has experience in roles that involve:\n",
      "*   Utilizing data analysis, visualization, and storytelling to enhance marketing strategies and user engagement.\n",
      "*   Designing and implementing data integration solutions for insightful reporting.\n",
      "*   Monitoring and controlling various maintenance activities, ensuring smooth operations and effective resource use.\n",
      "*   Collaborating on AI-based projects, from data integration to model development.\n",
      "\n",
      "**In essence, the resume presents a versatile individual capable of leveraging data and AI for strategic decision-making, while also possessing practical experience in operational and project management.**\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: This resume highlights a professional with a strong blend of technical and soft skills, primarily focused on data analysis, AI, and maintenance management.\n",
      "\n",
      "**Key Strengths:**\n",
      "\n",
      "*   **Data & AI Expertise:** Proficient in Machine Learning, Deep Learning, NLP, Generative AI, and tools like TensorFlow, Python (Numpy, Pandas, Matplotlib, Seaborn, Keras), SQL, PowerBI, and Looker Studio. Demonstrated experience in building RAG-based Q&A systems and real-time project dashboards.\n",
      "*   **Data Visualization & Storytelling:** Skilled in using Looker Studio for creating clear, actionable insights, improving marketing strategies, and driving data-driven decision-making.\n",
      "*   **Maintenance & Operations Management:** Experience in planning, coordinating, and monitoring maintenance activities (preventive, scheduled, breakdown), ensuring resource utilization, and managing materials and vendors.\n",
      "*   **Soft Skills:** Strong in time management, organization, leadership, communication, collaboration, and ensuring compliance and safety.\n",
      "\n",
      "**Work Experience Highlights:**\n",
      "\n",
      "The individual has experience in roles that involve:\n",
      "*   Utilizing data analysis, visualization, and storytelling to enhance marketing strategies and user engagement.\n",
      "*   Designing and implementing data integration solutions for insightful reporting.\n",
      "*   Monitoring and controlling various maintenance activities, ensuring smooth operations and effective resource use.\n",
      "*   Collaborating on AI-based projects, from data integration to model development.\n",
      "\n",
      "**In essence, the resume presents a versatile individual capable of leveraging data and AI for strategic decision-making, while also possessing practical experience in operational and project management.**\n"
     ]
    }
   ],
   "source": [
    "#  Run conversation\n",
    "print(\"1️⃣ First question\")\n",
    "res1 = agent.run(\"What are the skills mentioned?\")\n",
    "print(\"Answer:\", res1)\n",
    "\n",
    "print(\"\\n2️⃣ Follow-up\")\n",
    "res2 = agent.run(\"what is the work experience details?\")\n",
    "print(\"Answer:\", res2)\n",
    "\n",
    "print(\"\\n3️⃣ Ask again\")\n",
    "res3 = agent.run(\"Explain and summaries resume simply.\")\n",
    "print(\"Answer:\", res3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f2e7ae-6445-4e8f-8658-26cb6f6a7772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a9a27-2143-4b5d-a899-0e714ce6d4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
